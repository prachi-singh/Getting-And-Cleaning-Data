dim(andy)
str(andy)
summary(andy)
names(andy)
andy[1, "Weight"]
andy[30, "Weight"]
andy[which(andy$Day == 30), "Weight"]
andy[which(andy[,"Day"]==30), "Weight"]
subset(andy$Weight, andy$Day==30)
andy_start <- andy[1,"Weight"]
andy_end <- andy[30, "Weight"]
andy_loss <- andy_start - andy_end
andy_loss
?list.files
list.files(R.home())
file.info("diet_data")
list.files()
file.info("Chambers_-_Software_for_Data_Analysis_-_Programming_with_R.pdf")
files()
file
files
file.create("Hello")
ls()
list.files()
file.exists("Hello")
file.exists("Um")
file.remove("Hello")
list.files
list.files()
file.create("Um-hello")
file.rename("Um-hello", "Hello!")
list.files()
file.create("World")
file.append("Hello!", "World")
list.files()
?list.files
dir()
dir(all.files=TRUE)
dir(full.names=TRUE)
list.dirs(full.names=TRUE)
files <- list.files("Diet_Data")
files
files[1]
files[3:5]
files[2]
head(read.csv[3])
head(read.csv(files[3])
head(read.csv(files[3]))
files[3]
files_full <- list.files("diet_data", full.names=TRUE)
files_full
head(read.csv(files_full[3]))
andy_david <- rbind(andy, read.csv(files_full[2]))
andy_david
head(andy_david)
tail(andy_david)
day_25 <- andy_david[which(andy_david$Day == 25)]
day_25 <- andy_david[which(andy_david$Day == 25), ]
day_25
for (i in 1:5) print i
for (i in 1:5) {print i}
for (i in 1:5) print(i)
for (i in 1:5) { dat <- rbind(dat, read.csv(files_full[i]))}
dat <- data.frame()
dat
class(dat)
attributes(dat)
dim(dat)
for (i in 1:5) { dat <- rbind(dat, read.csv(files_full[i]))}
str(dat)
?str
list.files("diet_data/")
median(dat)
median(dat$Weight)
dat
median(dat$Weight, na.rm=TRUE)
dat_30 <- dat[which(dat[, "Day"] == 30),]
dat_30
dat[which(dat[,"Day"]==25), which(dat["Patient.Name",] == "John")]
dat[, which(dat["Patient.Name",] == "John")]
dat[, "John"]
dat[, names("John")]
dat[, dat$Patient.Name == "John"]
dat[which(dat["Patient.Name",]=="John")]
dat[which(dat[,"Patient.Name"]=="John")]
dat[which(dat[,"Patient.Name"]=="John"),]
dat[col="Age"]
dat[,"Age"]
x <- dat[,"Age"]
class(x)
class(dat)
median(dat_30$Weight)
weightmedian <- function(directory, day) {
files_list <- list.files(directory, full.names = TRUE)
dat <- data.frame()
for (i in 1:5) {
dat <- rbind(dat, read.csv(files_list[i]))
}
data_subset <- dat[which(dat[,"Day"] == day),]
median(dat_subset[,"Weight"], na.rm=TRUE)
}
weightmedian("diet_data", 25)
weightmedian <- function(directory, day) {
files_list <- list.files(directory, full.names = TRUE)
dat <- data.frame()
for (i in 1:5) {
dat <- rbind(dat, read.csv(files_list[i]))
}
dat_subset <- dat[which(dat[,"Day"] == day),]
median(dat_subset[,"Weight"], na.rm=TRUE)
}
weightmedian("diet_data", 25)
weightmedian("diet_data", 3)
weightmedian("diet_data", 30)
weightmedian(directory="diet_data", 30)
weightmedian(directory="diet_data", day =30)
?data.frame
getwd()
list.files("specdata")
pollutantmean <- function(directory, pollutant, id = 1:332) {
files_list <- list.files(directory, full.names = TRUE)
dat <- data.frame()
for (i in seq_along(files_list)) {
dat <- rbind(dat, read.csv(files_list[i]))
}
dat_subset <- dat[which(dat[, "ID"] == id),]
median(dat_subset[,pollutant], na.rm=TRUE)
}
pollutantmean("specdata", pollutant = "nitrate", id = 1:322)
pollutantmean(directory= "specdata", pollutant = "nitrate", id = 1:322)
pollutantmean <- function(directory, pollutant, id = 1:332) {
files_list <- list.files(directory, full.names = TRUE)
dat <- data.frame()
for (i in seq_along(files_list)) {
dat <- rbind(dat, read.csv(files_list[i]))
}
dat_subset <- dat[which(dat[, "ID"] == id),]
mean(dat_subset[,pollutant], na.rm=TRUE)
}
pollutantmean(directory= "specdata", pollutant = "nitrate", id = 1:322)
pollutantmean(directory= "specdata", pollutant = "nitrate", id = 23)
pollutantmean(directory= "specdata", pollutant = "sulfate", id = 1:10)
pollutantmean(directory= "specdata", pollutant = "nitrate", id = 70:72)
}
complete <- function(directory, id = 1:332) {
# --- Assert 'directory' is a character vector of length 1 indicating the
# location of the CSV files.  'id' is an integer vector indicating the
# monitor ID numbers to be used Return a data frame of the form: id nobs 1
# 117 2 1041 ...  where 'id' is the monitor ID number and 'nobs' is the
# number of complete cases
# --- Assert create an empty vector
nobsNum <- numeric(0)
for (cid in id) {
# --- Assert get data frame as ID
cDfr <- getmonitor(cid, directory)
# --- Assert count the number of complete cases and append to numeric
# vector
nobsNum <- c(nobsNum, nrow(na.omit(cDfr)))
}
# --- Assert return value is a data frame with TWO (2) columns
data.frame(id = id, nobs = nobsNum)
}
getmonitor <- function(id, directory, summarize = FALSE) {
# --- Assert 'id' is a vector of length 1 indicating the monitor ID
# number. The user can specify 'id' as either an integer, a character, or
# a numeric.  'directory' is a character vector of length 1 indicating the
# location of the CSV files 'summarize' is a logical indicating whether a
# summary of the data should be printed to the console; the default is
# FALSE
# --- Assert construct file name Directory is pre-appended to file name.
# Use sprintf() to add leading zeroes.  E.g. 'specdata/001.csv'
fileStr <- paste(directory, "/", sprintf("%03d", as.numeric(id)), ".csv",
sep = "")
# --- Assert read csv
rawDfr <- read.csv(fileStr)
# --- Assert summary if true
if (summarize) {
print(summary(rawDfr))
}
# --- Return value is a data frame
return(rawDfr)
complete("specdata", 1)
complete <- function(directory, id = 1:332) {
# --- Assert 'directory' is a character vector of length 1 indicating the
# location of the CSV files.  'id' is an integer vector indicating the
# monitor ID numbers to be used Return a data frame of the form: id nobs 1
# 117 2 1041 ...  where 'id' is the monitor ID number and 'nobs' is the
# number of complete cases
# --- Assert create an empty vector
nobsNum <- numeric(0)
for (cid in id) {
# --- Assert get data frame as ID
cDfr <- getmonitor(cid, directory)
# --- Assert count the number of complete cases and append to numeric
# vector
nobsNum <- c(nobsNum, nrow(na.omit(cDfr)))
}
# --- Assert return value is a data frame with TWO (2) columns
data.frame(id = id, nobs = nobsNum)
}
getmonitor <- function(id, directory, summarize = FALSE) {
# --- Assert 'id' is a vector of length 1 indicating the monitor ID
# number. The user can specify 'id' as either an integer, a character, or
# a numeric.  'directory' is a character vector of length 1 indicating the
# location of the CSV files 'summarize' is a logical indicating whether a
# summary of the data should be printed to the console; the default is
# FALSE
# --- Assert construct file name Directory is pre-appended to file name.
# Use sprintf() to add leading zeroes.  E.g. 'specdata/001.csv'
fileStr <- paste(directory, "/", sprintf("%03d", as.numeric(id)), ".csv",
sep = "")
# --- Assert read csv
rawDfr <- read.csv(fileStr)
# --- Assert summary if true
if (summarize) {
print(summary(rawDfr))
}
# --- Return value is a data frame
return(rawDfr)
}
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete <- function(directory, id = 1:332) {
nobsNum <- numeric(0)
for (cid in id) {
cDfr <- getmonitor(cid, directory)
nobsNum <- c(nobsNum, nrow(na.omit(cDfr)))
}
data.frame(id = id, nobs = nobsNum)
}
getmonitor <- function(id, directory, summarize = FALSE) {
fileStr <- paste(directory, "/", sprintf("%03d", as.numeric(id)), ".csv",
sep = "")
rawDfr <- read.csv(fileStr)
if (summarize) {
print(summary(rawDfr))
}
return(rawDfr)
}
complete("specdata", 30:25)
complete <- function(directory, id = 1:332) {
nobsNum <- numeric(0)
for (cid in id) {
cDfr <- getmonitor(cid, directory)
nobsNum <- c(nobsNum, nrow(na.omit(cDfr)))
}
data.frame(id = id, nobs = nobsNum)
}
getmonitor <- function(id, directory, summarize = FALSE) {
fileStr <- paste(directory, "/", sprintf("%03d", as.numeric(id)), ".csv",
sep = "")
rawDfr <- read.csv(fileStr)
print(rawDfr)
if (summarize) {
print(summary(rawDfr))
}
return(rawDfr)
}
complete("specdata", 30:25)
getwd()
help.start()
x <- rnorm(50)
y <- rnorm(x)
plot(x,y)
ls()
rm(x,y)
ls()
x <- 1:20
s
x
class(x)
w <- 1 + sqrt(x)/2
w
class(w)
dummy <- data.frame(x=x, y=x + rnorm(x)*w)
dummy
fm <- lm(y ~ x, data=dummy)
summary(fm)
fm1 <- lm(y ~ x, data=dummy, weight=1/w^2)
summary(fm1)
attach(dummy)
lrf <- lowess(x,y)
plot(x,y)
help(if)
help('if')
??solve
example(lapply)
objects()
q()
x <- 5
print(x)
parent <- function(){
child <- function () {
print(x)
x <<- x + 5
print(x)
}
child()
print(x)
}
parent()
}
grandparent <- function() {
x <- 5
print(x)
parent <- function(){
child <- function () {
print(x)
x <<- x + 5
print(x)
}
child()
print(x)
}
parent()
}
grandparent()
browser(grandparent)
debug(grandparent)
grandparent()
grandparent()
##Getting And Cleaning Data, Peer Assessment Assignment
##Prachi Singh, Jan 24th, 2015
##run_analysis.r
##Script to merge and analyze the training and test activity datasets of 6 levels
##of activities performed by 30 volunteers.
#Ensure that UCI HAR Dataset folder is in your current working directory.
#Need to have data.table, reshape2, and tidyr packages installed to run this script.
#Load required libraries: data.table, reshape2, tidyr
require("data.table")
require("reshape2")
require("tidyr")
#Load activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
#Load data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
#Clean up column names to make more readable, using gsub() pattern replacement
features <- gsub('[-()]', '', features)
features <- gsub("^t", "Time_", features)
features <- gsub("^f", "Freq_", features)
features <- gsub("*Gyro*", "AngularVelocity_", features)
features <- gsub("*Acc*", "Acceleration_", features)
#Use grepl to only extract measurements on the mean and standard deviation for each measurement.
#grepl() returns logical vector of columns that match.
#Our desired features have -mean() or -std() as a part of the column name.
select_features <- grepl("mean|std", features)
#Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) <- features
#Extract measurements on the mean and standard deviation for each measurement.
X_test <- X_test[,select_features]
#Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) <- c("Activity_ID", "Activity_Label")
names(subject_test) <- "Subject"
#Column bind the entire test data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
#Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) <- features
#Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,select_features]
#Load activity data
y_train[,2] <- activity_labels[y_train[,1]]
names(y_train) <- c("Activity_ID", "Activity_Label")
names(subject_train) = "Subject"
#Column bind training dataset
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
#Merge test and train datasets
combined_data <- rbind(test_data, train_data)
#Differentiate ID variables and Measured variables and melt dataset
id_labels <- c("Subject", "Activity_ID", "Activity_Label")
data_labels <- setdiff(colnames(combined_data), id_labels)
melt_data <- melt(combined_data, id = id_labels, measure.vars = data_labels)
#Apply mean function to dataset using dcast function
tidy_dataset <- dcast(melt_data, Subject + Activity_Label ~ variable, mean)
write.table(tidy_dataset, file = "./uci_har_tidy_data.txt")
write.table(tidy_dataset, file="./uci_har_tidy_data.csv")
setwd("~/DataScienceJHU/Getting-And-Cleaning-Data/")
##Getting And Cleaning Data, Peer Assessment Assignment
##Prachi Singh, Jan 24th, 2015
##run_analysis.r
##Script to merge and analyze the training and test activity datasets of 6 levels
##of activities performed by 30 volunteers.
#Ensure that UCI HAR Dataset folder is in your current working directory.
#Need to have data.table, reshape2, and tidyr packages installed to run this script.
#Load required libraries: data.table, reshape2, tidyr
require("data.table")
require("reshape2")
require("tidyr")
#Load activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
#Load data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
#Clean up column names to make more readable, using gsub() pattern replacement
features <- gsub('[-()]', '', features)
features <- gsub("^t", "Time_", features)
features <- gsub("^f", "Freq_", features)
features <- gsub("*Gyro*", "AngularVelocity_", features)
features <- gsub("*Acc*", "Acceleration_", features)
#Use grepl to only extract measurements on the mean and standard deviation for each measurement.
#grepl() returns logical vector of columns that match.
#Our desired features have -mean() or -std() as a part of the column name.
select_features <- grepl("mean|std", features)
#Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) <- features
#Extract measurements on the mean and standard deviation for each measurement.
X_test <- X_test[,select_features]
#Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) <- c("Activity_ID", "Activity_Label")
names(subject_test) <- "Subject"
#Column bind the entire test data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
#Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) <- features
#Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,select_features]
#Load activity data
y_train[,2] <- activity_labels[y_train[,1]]
names(y_train) <- c("Activity_ID", "Activity_Label")
names(subject_train) = "Subject"
#Column bind training dataset
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
#Merge test and train datasets
combined_data <- rbind(test_data, train_data)
#Differentiate ID variables and Measured variables and melt dataset
id_labels <- c("Subject", "Activity_ID", "Activity_Label")
data_labels <- setdiff(colnames(combined_data), id_labels)
melt_data <- melt(combined_data, id = id_labels, measure.vars = data_labels)
#Apply mean function to dataset using dcast function
tidy_dataset <- dcast(melt_data, Subject + Activity_Label ~ variable, mean)
write.table(tidy_dataset, file = "./uci_har_tidy_data.txt")
write.table(tidy_dataset, file="./uci_har_tidy_data.csv")
read.table("./uci_har_tidy_data.csv")
setwd("./Getting-And-Cleaning-Data/")
setwd("~/DataScienceJHU/Getting-And-Cleaning-Data/Getting-And-Cleaning-Data/")
?write.table
write.table(tidy_dataset, file="./uci_har_tidy_data.csv", row.names=FALSE)
##Getting And Cleaning Data, Peer Assessment Assignment
##Prachi Singh, Jan 24th, 2015
##run_analysis.r
##Script to merge and analyze the training and test activity datasets of 6 levels
##of activities performed by 30 volunteers.
#Ensure that UCI HAR Dataset folder is in your current working directory.
#Need to have data.table, reshape2, and tidyr packages installed to run this script.
#Load required libraries: data.table, reshape2, tidyr
require("data.table")
require("reshape2")
require("tidyr")
#Load activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
#Load data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
#Clean up column names to make more readable, using gsub() pattern replacement
features <- gsub('[-()]', '', features)
features <- gsub("^t", "Time_", features)
features <- gsub("^f", "Freq_", features)
features <- gsub("*Gyro*", "AngularVelocity_", features)
features <- gsub("*Acc*", "Acceleration_", features)
#Use grepl to only extract measurements on the mean and standard deviation for each measurement.
#grepl() returns logical vector of columns that match.
#Our desired features have -mean() or -std() as a part of the column name.
select_features <- grepl("mean|std", features)
#Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) <- features
#Extract measurements on the mean and standard deviation for each measurement.
X_test <- X_test[,select_features]
#Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) <- c("Activity_ID", "Activity_Label")
names(subject_test) <- "Subject"
#Column bind the entire test data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
#Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) <- features
#Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,select_features]
#Load activity data
y_train[,2] <- activity_labels[y_train[,1]]
names(y_train) <- c("Activity_ID", "Activity_Label")
names(subject_train) = "Subject"
#Column bind training dataset
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
#Merge test and train datasets
combined_data <- rbind(test_data, train_data)
#Differentiate ID variables and Measured variables and melt dataset
id_labels <- c("Subject", "Activity_ID", "Activity_Label")
data_labels <- setdiff(colnames(combined_data), id_labels)
melt_data <- melt(combined_data, id = id_labels, measure.vars = data_labels)
#Apply mean function to dataset using dcast function
tidy_dataset <- dcast(melt_data, Subject + Activity_Label ~ variable, mean)
write.table(tidy_dataset, file = "./uci_har_tidy_data.txt", row.names=FALSE)
write.table(tidy_dataset, file="./uci_har_tidy_data.csv", row.names=FALSE)
read.table("./uci_har_tidy_data.txt")
